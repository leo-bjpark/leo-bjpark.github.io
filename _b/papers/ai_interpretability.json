[{
    "title": "Mechanistic Indicators of Understanding in Large Language Models",
    "authors": "Pierre Beckmann",
    "year": 2025,
    "venue": "NA",
    "save_date": "2026-01-14",
    "hover_memo": "이 논문은 대규모 언어 모델의 ‘이해’를 단순한 모방 대 진짜 이해라는 이분법으로 보지 않고, 내부 계산 구조의 조직화 수준에 따라 중첩적으로 나타나는 계층적 현상으로 재정의한다. 개념적 이해는 잠재 공간의 feature 형성으로, 세계-상태 이해는 조건적·사실적 인과 관계의 학습으로, 원리적 이해는 암기를 넘어선 압축된 회로의 발견으로 설명되며, 이들은 서로 분리된 단계가 아니라 동일한 내부 메커니즘 위에 겹쳐서 작동하는 이해의 층위로 제시된다. 기계적 해석 가능성 연구는 이러한 층위들이 실제로 모델 내부에서 어떻게 구현되는지를 보여주며, 이를 철학적 이해 이론과 결합함으로써 저자들은 LLM의 이해를 인간과 동일시하거나 전면 부정하는 논쟁을 넘어, AI 이해가 인간 이해와 어떻게 정렬되고 어디서 구조적으로 다른지를 분석하는 비교적·기계론적 인식론의 가능성을 제안한다."
}
]