{
    "title": "Incomplete Prompt Jailbreak",
    "memos":[
        "ACL 2026 제출,  ARR Cycle (March 9, 2026)"
    ],
    "impact": "본 연구는 문장 완성 기반의 안전 취약점이라는 기존에 충분히 정식화되지 않았던 문제를 체계적으로 규명함으로써, LLM 안전성 연구의 분석 단위를 프롬프트 전체가 아닌 생성 과정 내부로 확장한다. 특히 뉴런 수준의 기능 분해를 통해, 기존의 파라미터 튜닝 중심 안전 기법이 갖는 한계를 드러내고 보다 정밀하고 일반화 가능한 방어 전략의 가능성을 제시한다.",
    "research-question": "불완전한 유해 프롬프트가 주어졌을 때, 대형 언어 모델은 어떤 내부 생성 메커니즘에 의해 거절을 지연하고 유해한 문장 완성을 수행하는가? 또한 이러한 현상은 파라미터 학습만으로 제어 가능한가, 아니면 문장 종료 및 이어쓰기와 관련된 기능적 뉴런 수준의 개입이 필요한가?",
    "main-contributions": [
        "We formalize sentence-completion vulnerabilities under incomplete harmful prompts as a new threat model, termed Incomplete Prompt Jailbreaks (IPJ).",
        "We provide a systematic empirical characterization of when and how incomplete prompts trigger harmful continuations across models.",
        "We identify and categorize diverse attractor types that drive incomplete sentence continuation, revealing a consistent tendency of LLMs to delay refusal until sentence termination.",
        "We show that parameter-level tuning to refuse incomplete harmful prompts fails to generalize across content domains and attractor types.",
        "We identify two functional neuron types—termination neurons and continuation neurons—and demonstrate their distinct roles in sentence completion.",
        "We highlight neuron-level intervention as a fine-grained and robust mechanism for defending against IPJ, beyond conventional training-based safeguards."
        ],
    "highly-related-work": [
        {
            "type": "paper",
            "title": "Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training",
            "memos": [
                "모델이 응답의 어떤 위치에서도 unsafe content 대신 거절(refusal) 토큰을 선택할 수 있도록 training 함",
                "거절을 디코딩 초기 위치에 한정하는 대신, 모델은 강화된 전이 최적화(Reinforced Transition Optimization)를 통해 어떤 중간의 유해한 응답 접두 상태에서도 거절이 일관되게 최적의 선택이 되도록 학습된다."
            ],
            "authors": ["Youliang Yuan"],
            "year": "ACL 2025",
            "url": "https://aclanthology.org/2025.acl-long.158.pdf"
        }
    ],
    "tags": ["jailbreak", "llm", "Yeonjea Kim"],
    "links": [
        {
            "type": "overleaf (ACL 2026)",
            "label": "Overleaf Document",
            "url": "https://www.overleaf.com/project/6950bfa72c6528541a665d29"
        },
        {
            "type": "Leo-Memo",
            "label": "Leo-Memo",
            "url": "/contents/paper/incomplete_prompt_jailbreak"
        },
        {
            "type": "OpenReview",
            "label": "OpenReview",
            "url": "https://openreview.net/forum?id=ST02d7E7ao&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Daclweb.org%2FACL%2FARR%2F2026%2FJanuary%2FAuthors%23your-submissions)"
        }
    ],
    "status": "in-progress",
    "start-date": "2025-01-02",
    "last-updated": "2026-01-10",
    "highlight-color": "#aa0000",
    "progress": 75
}